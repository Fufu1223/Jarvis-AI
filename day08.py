import json
import os
import subprocess # æ–°å¢ï¼šç”¨äºæ‰§è¡Œç³»ç»Ÿå‘½ä»¤
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv("key.env")

api_key = os.getenv("DEEPSEEK_API_KEY")

client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com")


def load_memory(filepath: str) -> list:
    """
    åŠŸèƒ½: ä»æŒ‡å®šè·¯å¾„è¯»å– JSON æ–‡ä»¶
    å‚æ•° filepath: æ–‡ä»¶è·¯å¾„ (str)
    è¿”å›: èŠå¤©è®°å½•åˆ—è¡¨ (list)
    """
    # --- å¡«ç©ºåŒºåŸŸå¼€å§‹ ---
    try:
        # æ³¨æ„ï¼šè¿™é‡Œæ‰“å¼€æ–‡ä»¶æ—¶ï¼Œä¸è¦å†™æ­» "memory.json"ï¼Œè¦ç”¨å˜é‡ filepath
        with open(filepath, "r", encoding="utf-8") as f:
            data = json.load(f) # æˆ‘ä»¬æŠŠè¯»åˆ°çš„ä¸œè¥¿æš‚å­˜åˆ° data å˜é‡
    except FileNotFoundError:
        data = [] # å¦‚æœæ‰¾ä¸åˆ°æ–‡ä»¶ï¼Œå°±åˆ›å»ºä¸€ä¸ªç©ºåˆ—è¡¨
    # --- å¡«ç©ºåŒºåŸŸç»“æŸ ---
    
    # æœ€åï¼ŒæŠŠç»“æœäº¤å‡ºå»
    return data

def save_memory(filepath: str, data: list) -> None:
    """
    åŠŸèƒ½: å°†æ•°æ®å†™å…¥ JSON æ–‡ä»¶
    å‚æ•° filepath: æ–‡ä»¶è·¯å¾„ (str)
    å‚æ•° data: è¦ä¿å­˜çš„æ•°æ® (list)
    è¿”å›: None
    """
    # è¿™é‡Œçš„ "w" æ¨¡å¼ä¼šè¦†ç›–å†™å…¥ï¼Œç¬¦åˆæˆ‘ä»¬ä¹‹å‰çš„é€»è¾‘
    with open(filepath, "w", encoding="utf-8") as f:
        # ğŸ‘‡ è¯·æŠŠåŸæ¥ json.dump çš„é€»è¾‘æ¬è¿›æ¥
        # æç¤º: ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯è¦å­˜çš„æ•°æ®å˜é‡åï¼Œç¬¬äºŒä¸ªæ˜¯æ–‡ä»¶å¯¹è±¡ f
        json.dump(data, f, ensure_ascii=False, indent=4)

def get_ai_response(messages: list) -> str:
    """
    åŠŸèƒ½: è°ƒç”¨ DeepSeek API è·å–å›å¤
    å‚æ•° messages: èŠå¤©è®°å½•åˆ—è¡¨ (list)
    è¿”å›: AI çš„å›å¤æ–‡æœ¬ (str)
    """
    # ğŸŒŸ 25w å¹´è–ªçº§ç»†èŠ‚: åŠ ä¸Š try-except é˜²æ­¢æ–­ç½‘å¯¼è‡´ç¨‹åºå´©æºƒ
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            # ğŸ‘‡ è¿™é‡Œè¦æŠŠå‚æ•°ä¼ è¿›å»
            messages=messages
        )
        # ğŸ‘‡ æå–å›å¤æ–‡æœ¬å¹¶è¿”å›
        return response.choices[0].message.content
        
    except Exception as e:
        # å¦‚æœå‡ºé”™äº† (æ¯”å¦‚æ–­ç½‘ã€æ²¡é’±äº†)ï¼Œæ‰“å°é”™è¯¯å¹¶è¿”å›ä¸€ä¸ªæç¤º
        print(f"âŒ API è°ƒç”¨å¤±è´¥: {e}")
        return "ï¼ˆè´¾ç»´æ–¯æ‰çº¿äº†ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ...ï¼‰"

# ... (ä¸Šé¢æ˜¯ä½ å†™å¥½çš„ä¸‰ä¸ªå‡½æ•°ï¼šload_memory, save_memory, get_ai_response) ...

def execute_command(text: str) -> None:
    """
    åŠŸèƒ½: æ ¹æ®æ–‡æœ¬å…³é”®è¯æ‰§è¡Œç³»ç»Ÿå‘½ä»¤ (ç®€æ˜“ç‰ˆæ„å›¾è¯†åˆ«)
    """
    # è½¬æ¢ä¸ºå°å†™ï¼Œé˜²æ­¢ç”¨æˆ·è¾“å…¥ Calc å¯¼è‡´åŒ¹é…å¤±è´¥
    text = text.lower()
    
    # ğŸ‘‡ ä¿®æ”¹è¿™ä¸€è¡Œï¼Œå¤šåŠ ä¸€ä¸ª "or"
    if "è®¡ç®—å™¨" in text or "è®¡ç®—æœº" in text or "calc" in text:
        print("âœ… å‘½ä¸­è§„åˆ™ï¼šè®¡ç®—å™¨")
        print("ğŸ”§ æ­£åœ¨æ‰§è¡Œ subprocess...")
        subprocess.Popen("start calc", shell=True)
    
    elif "è®°äº‹æœ¬" in text or "notepad" in text:
        print("ğŸ“ æ£€æµ‹åˆ°æŒ‡ä»¤ï¼šæ­£åœ¨å¯åŠ¨è®°äº‹æœ¬...")
        subprocess.Popen("start notepad", shell=True)

def main():
    """
    ä¸»ç¨‹åºå…¥å£ï¼šè´Ÿè´£è°ƒåº¦æ‰€æœ‰æ¨¡å—
    """
    print("ğŸš€ è´¾ç»´æ–¯ (25wå·¥ç¨‹ç‰ˆ) æ­£åœ¨å¯åŠ¨...")
    
    # 1. å®šä¹‰è®°å¿†æ–‡ä»¶è·¯å¾„
    memory_file = "memory.json"
    
    # 2. è°ƒç”¨å‡½æ•°ï¼šåŠ è½½è®°å¿†
    # æç¤ºï¼šæŠŠ memory_file ä¼ è¿›å»ï¼ŒæŠŠç»“æœèµ‹å€¼ç»™ chat_history
    chat_history = load_memory(memory_file)

    while True:
        user_input = input("\nä½ è¯´: ")
        
        # ... (ä¸Šé¢æ˜¯ user_input = input(...) ) ...
        
        if user_input.lower() == "quit":
            print("ğŸ‘‹ å†è§ï¼")
            break
        
        # ğŸ”¥ æ–°å¢ï¼šå…ˆè®©æœºæ¢°æ‰‹æ£€æŸ¥ä¸€ä¸‹æœ‰æ²¡æœ‰èƒ½å¹²çš„æ´»
        # åªè¦ç”¨æˆ·è¯´äº†â€œè®¡ç®—å™¨â€ï¼Œç›´æ¥å¼¹çª—ï¼Œä¸éœ€è¦é—® AI
        execute_command(user_input)
        
        # ... (ä¸‹é¢ç»§ç»­èµ° chat_history.append ... ) ...
        
        # 3. è®°å½•ç”¨æˆ·è¾“å…¥
        chat_history.append({"role": "user", "content": user_input})
        
        # 4. è°ƒç”¨å‡½æ•°ï¼šè·å– AI å›å¤ (æœ€å…³é”®çš„ä¸€æ­¥ï¼)
        # æç¤ºï¼šè°ƒç”¨ get_ai_responseï¼ŒæŠŠ chat_history ä¼ ç»™å®ƒ
        # ç»“æœèµ‹å€¼ç»™ ai_msg
        ai_msg = get_ai_response(chat_history)
        
        print(f"ğŸ¤– AI: {ai_msg}")
        
        # 5. è®°å½• AI å›å¤
        chat_history.append({"role": "assistant", "content": ai_msg})
        
        # 6. è°ƒç”¨å‡½æ•°ï¼šä¿å­˜è®°å¿†
        # æç¤ºï¼šæŠŠ memory_file å’Œ chat_history ä¼ è¿›å»
        save_memory(memory_file, chat_history)

# æ ‡å‡†ç¨‹åºçš„å¯åŠ¨å¼€å…³
if __name__ == "__main__":
    main()