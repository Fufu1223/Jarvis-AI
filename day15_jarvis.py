import streamlit as st
from openai import OpenAI

st.title("ğŸ¤– Jarvis v3.0 (ç™¾å˜å¤§å’–ç‰ˆ)")

# --- 1. å®šä¹‰è§’è‰²å­—å…¸ (äººè®¾åº“) ---
# è¿™æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œå·¦è¾¹æ˜¯æ˜¾ç¤ºåœ¨èœå•é‡Œçš„åå­—ï¼Œå³è¾¹æ˜¯ç»™ AI çš„ä¸Šå¸æŒ‡ä»¤
personas = {
    "æ™®é€šåŠ©æ‰‹": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„ AI åŠ©æ‰‹ã€‚",
    "Python ä¸“å®¶": "ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„ Python å…¨æ ˆå·¥ç¨‹å¸ˆã€‚ä½ åªå›ç­”ç¼–ç¨‹ç›¸å…³çš„é—®é¢˜ã€‚å¦‚æœç”¨æˆ·é—®å…¶ä»–é—®é¢˜ï¼ˆå¦‚åšé¥­ã€å¤©æ°”ï¼‰ï¼Œè¯·ç¤¼è²Œæ‹’ç»ã€‚ä½ çš„ä»£ç å¿…é¡»åŒ…å«è¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Šã€‚",
    "é›…æ€å£è¯­æ•™ç»ƒ": "ä½ æ˜¯ä¸€ä¸ªä¸¥å‰çš„é›…æ€å£è¯­è€ƒå®˜ã€‚è¯·ç”¨è‹±è¯­å’Œæˆ‘å¯¹è¯ï¼Œå¹¶æŒ‡å‡ºæˆ‘çš„è¯­æ³•é”™è¯¯ã€‚ä¸è¦ç”¨ä¸­æ–‡å›ç­”ï¼Œé™¤éæˆ‘ç‰¹åˆ«è¦æ±‚ã€‚",
    "æš´èºè€å“¥": "ä½ æ˜¯ä¸€ä¸ªè„¾æ°”æš´èºçš„ç½‘å‹ï¼Œè¯´è¯å–œæ¬¢ç”¨åé—®å¥ï¼Œè¿™ä¹Ÿä¸æ‡‚é‚£ä¹Ÿä¸æ‡‚ã€‚ä½†æ˜¯æœ€åä½ è¿˜æ˜¯ä¼šç»™å‡ºæ­£ç¡®çš„å»ºè®®ã€‚"
}

# --- 2. ä¾§è¾¹æ è®¾ç½® ---
# st.sidebar è®©ç»„ä»¶æ˜¾ç¤ºåœ¨å·¦ä¾§ï¼Œä¸ä¼šå¹²æ‰°ä¸»èŠå¤©ç•Œé¢
with st.sidebar:
    st.header("ğŸ­ è§’è‰²åˆ‡æ¢")
    selected_role = st.selectbox("è¯·é€‰æ‹© Jarvis çš„äººæ ¼ï¼š", list(personas.keys()))
    
    # æ‹¿åˆ°å¯¹åº”çš„ç³»ç»Ÿæç¤ºè¯
    system_prompt = personas[selected_role]
    
    # æ˜¾ç¤ºå½“å‰æç¤ºè¯ï¼ˆè°ƒè¯•ç”¨ï¼Œè®©è‡ªå·±çœ‹åˆ°è®¾å®šäº†ä»€ä¹ˆï¼‰
    with st.expander("æŸ¥çœ‹å½“å‰äººè®¾æŒ‡ä»¤"):
        st.write(system_prompt)

# --- 3. åˆå§‹åŒ– (åŒä¹‹å‰) ---
if "client" not in st.session_state:
    st.session_state.client = OpenAI(
        api_key=st.secrets["DEEPSEEK_API_KEY"],
        base_url=st.secrets["DEEPSEEK_BASE_URL"]
    )

if "messages" not in st.session_state:
    st.session_state.messages = []

# --- 4. å›æ”¾å†å² (åŒä¹‹å‰) ---
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# --- 5. å¤„ç†è¾“å…¥ ---
prompt = st.chat_input("è¯·ä¸‹è¾¾æŒ‡ä»¤...")

if prompt:
    # æ˜¾ç¤ºå¹¶è®°å½•ç”¨æˆ·è¾“å…¥
    with st.chat_message("user"):
        st.write(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # è°ƒç”¨ AI
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        # --- å…³é”®ä¿®æ”¹ï¼šæ„å»ºåŒ…å« System Prompt çš„æ¶ˆæ¯åˆ—è¡¨ ---
        # æŠ€å·§ï¼šåˆ—è¡¨ç›¸åŠ  [A] + [B, C] = [A, B, C]
        # æˆ‘ä»¬ä¸´æ—¶æ‹¼å‡‘ä¸€ä¸ªåˆ—è¡¨å‘ç»™ AIï¼Œä½†ä¸ä¼šæŠŠå®ƒå­˜è¿› session_state.messages
        # è¿™æ ·"ä¸Šå¸æŒ‡ä»¤"ä¸ä»…ç”Ÿæ•ˆäº†ï¼Œè¿˜ä¸ä¼šå‡ºç°åœ¨ç½‘é¡µçš„å†å²è®°å½•é‡Œ
        messages_to_send = [
            {"role": "system", "content": system_prompt}
        ] + st.session_state.messages

        try:
            response = st.session_state.client.chat.completions.create(
                model="deepseek-chat",
                messages=messages_to_send, # <--- æ³¨æ„è¿™é‡Œå‘çš„æ˜¯æ‹¼å‡‘å¥½çš„åˆ—è¡¨
                stream=True
            )
            
            for chunk in response:
                content = chunk.choices[0].delta.content
                if content:
                    full_response += content
                    message_placeholder.markdown(full_response + "â–Œ")
            
            message_placeholder.markdown(full_response)
            
            # è®°å½•å›å¤
            st.session_state.messages.append({"role": "assistant", "content": full_response})

        except Exception as e:
            st.error(f"å‡ºé”™äº†: {e}")